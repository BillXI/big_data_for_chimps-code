# Images decking should create. Use these labels for the 'decking build'
# command, or use 'all' to run all of them.
images:
  "bd4c/deb_proxy":        "./img/deb_proxy"
  "bd4c/baseimage":        "./img/baseimage"
  "bd4c/hadoop_base":      "./img/hadoop_base"
  "bd4c/hadoop_nn":        "./img/hadoop_nn"
  "bd4c/hadoop_rm":        "./img/hadoop_rm"
  "bd4c/hadoop_snn":       "./img/hadoop_snn"
  # "bd4c/hadoop_hue":       "./img/hadoop_hue"
  "bd4c/hadoop_worker":    "./img/hadoop_worker"
  "bd4c/hadoop_solo":    "./img/hadoop_solo"

# Containers to define. Options here correspond to common 'docker run' options.
containers:
  host_filer:
    image:       "blalor/docker-hosts"
    extra:       "/srv/hosts" # --domain-name=bd4c
    mount:
      - "/var/lib/docker/hosts:/srv/hosts"
      - "/var/run/docker.sock:/var/run/docker.sock"
    hostname:     "host-filer"

  # These containers have a directory given in "images" above, so they are built
  # locally from the corresponding Dockerfile
  deb_proxy:
    # # name of the image to use
    image:        "bd4c/deb_proxy"
    port:         [ "10022:22", "10000:10000" ]
    mount:        ["/tmp/deb_proxy:/bulk/deb_proxy"]
    hostname:     "deb-proxy"

  baseimage:      "bd4c/baseimage"

  hadoop_base:
    image:        "bd4c/hadoop_base"
    port:         [ "10122:22" ]

  hadoop_lounge:
    image:        "bd4c/hadoop_base"
    hostname:     "lounge"
    port:         [ "9022:22", "8888:8888" ]
    dependencies:
      - "hadoop_nn:nn"
      - "hadoop_rm:nn"
      - "hadoop_worker:worker"

  hadoop_solo:
    image:        "bd4c/hadoop_solo"
    # node mgr:  console http 8042, localizer 8040, ipc 8041
    # data node: console http 50075, ipc 50020, xceiver 50010
    # 8040, 8041, 50020, 50010, 8030, 8031, 8032, 8033, 13562, 10020, 10033, 8020, 50090
    port:         [ "9922:22", "9001:8888", "9002:50070", "9003:8088", "9004:8042", "9905:50075", "9906:19888"  ]
    mount:
      - "/tmp/solo/hadoop/log:/bulk/hadoop/log:rw"
    hostname:     "solo"


  #
  # TODO: We have hardcoded port mappings to the docker host, which is
  # convenient. It also however forces us to have a one-worker-only cluster.
  # Make it be one hero worker and a pool of 0..n anonymous workers (or just a
  # sea of anonymous workers)
  #
  hadoop_worker:
    image:        "bd4c/hadoop_worker"
    # node mgr:  console http 8042, localizer 8040, ipc 8041
    # data node: console http 50075, ipc 50020, xceiver 50010
    port:         [ "9122:22", "8042:8042", "50075:50075", 8040, 8041, 50020, 50010 ]
    dependencies:
      - "hadoop_nn:nn"
      - "hadoop_rm:rm"
    mount:
      - "/var/lib/docker/hosts:/etc/hosts:ro"
      - "/tmp/bulk/hadoop/log:/bulk/hadoop/log:rw"
    hostname:     "worker"

  #
  # hadoop_hue:
  #   image:        "bd4c/hadoop_base"
  #   hostname:     "hue"
  #   # http 8888
  #   port:         [ "9222:22", "8888:8888" ]

  hadoop_rm:
    image:        "bd4c/hadoop_rm"
    hostname:     "rm"
    # rsrc mgr: console http 8088; scheduler 8030; tracker 8031; ipc 8032; admin 8033, shuffle 13562;
    # history:  console 19888 / https 19890, ipc 10020, admin 10033
    port:         [ "9322:22", "8088:8088", "8030:8030", "8031:8031", "8032:8032", "8033:8033", "13562:13562", "19888:19888", "10020:10020", "10033:10033" ]
    dependencies:
      - "hadoop_nn:nn"
    mount:
      - "/var/lib/docker/hosts:/etc/hosts:ro"
      - "/tmp/bulk/hadoop/log:/bulk/hadoop/log:rw"

  hadoop_nn:
    image:        "bd4c/hadoop_nn"
    hostname:     "nn"
    # console http 50070; ipc 8020
    port:         [ "9422:22", "50070:50070", "8020:8020" ]
    mount:
       # dynamic /etc/hosts file
      - "/var/lib/docker/hosts:/etc/hosts:ro"
      - "/tmp/bulk/hadoop/log:/bulk/hadoop/log:rw"

  hadoop_snn:
    image:        "bd4c/hadoop_snn"
    hostname:     "snn"
    # checkpoint api http 50090
    port:         [ "9522:22", 50090 ]
    dependencies:
      - "hadoop_nn:nn"
    mount:
      - "/var/lib/docker/hosts:/etc/hosts:ro"
      - "/tmp/bulk/hadoop/log:/bulk/hadoop/log:rw"

  # Zookeeper   -- client 2181, ipc 2888, election 3888, JMX 9010, failover 8019
  # Httpfs      -- admin 14001, rest 14000
  # Journalnode -- 8480, 8485,
  # HDFS-NFS    -- gateway 2049, mountd 4242, portmap 111
  # Failover    -- 8018

clusters:
  helpers:
    - host_filer
    - deb_proxy
  dev:
    - hadoop_nn
    - hadoop_rm
    - hadoop_snn
    - hadoop_worker
    - hadoop_lounge
  han:
    - hadoop_solo

groups:
  helpers:
    containers:
      deb_proxy:        { port: ["10022:22","10000:10000"] }
